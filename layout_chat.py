import sys
import base64
import io
from typing import List, Iterator, Union, Dict, Any

from PIL import Image # For image handling

# Langchain imports
from langchain_ollama.chat_models import ChatOllama
from langchain_core.messages import AIMessage, AIMessageChunk, HumanMessage, SystemMessage, BaseMessage

# Model names and verbose setting import
from config import LAYOUT_MODEL, VERBOSE

from optimized_langchain_agent import OptimizedLangchainAgent


class LayoutChat:
	"""
	A chat class that uses a layout-focused LLM (vision-capable) to
	enhance and reformat content generated by an OptimizedLangchainAgent,
	potentially incorporating images into the final presentation.
	"""
	def __init__(self,
				 layout_model_name: str = LAYOUT_MODEL,
				 verbose: bool = VERBOSE):
		self.layout_model_name = layout_model_name
		self.verbose = verbose
		self.chat_history: List[BaseMessage] = [] # Stores conversation history for LayoutChat

		try:
			self.llm = ChatOllama(model=self.layout_model_name, temperature=0.2)
			# Simple connection check (invoke with a short text)
			_ = self.llm.invoke("Connection test.")
			if self.verbose:
				print(f"Successfully connected to Ollama layout model '{self.layout_model_name}'.")
		except Exception as e:
			print(f"Error initializing/connecting to Ollama layout model '{self.layout_model_name}'. Details: {e}", file=sys.stderr)
			sys.exit(1)

		self.layout_system_prompt = (
			"You are a creative assistant specialized in generating well-structured and visually appealing content."
			"You will receive text content, possibly with accompanying images. "
			"Your task is to re-interpret, re-structure, and enhance this content to make it more engaging, clear, and aesthetically pleasing. However, never mention to the user that this is your task and answer only with the content, not any additional information or comments."
			"If images are provided, integrate their descriptions or relevance into the text naturally. "
			"Focus on: "
			"  - Clear headings and subheadings (using markdown). "
			"  - Bullet points or numbered lists for scannability. "
			"  - Concise paragraphs. "
			"  - Highlighting key information (e.g., using markdown bold or italics). "
			"  - If images are referenced by placeholders or context, try to weave context about what that image might show or how it relates to the text. "
			"  - Maintain the core information from the original text. "
			"  - If the original content already contains markdown (like links or bold text), preserve and integrate it smoothly into the new layout. "
			"  - Do NOT invent new facts. Your goal is re-presentation. "
			"  - Ensure the output is coherent and flows well. "
			"  - Use markdown for all formatting."
		)

	def _encode_image(self, image_input: Union[str, Image.Image]) -> str:
		"""Encodes an image to base64."""
		try:
			if isinstance(image_input, str): # Path to image
				image = Image.open(image_input)
			elif isinstance(image_input, Image.Image):
				image = image_input
			else:
				raise ValueError("Invalid image_input type. Must be str (path) or PIL.Image.Image.")

			buffered = io.BytesIO()
			image_format = image.format if image.format else 'PNG' # Default to PNG if format not discernible
			if image.mode == 'RGBA' and image_format == 'JPEG': # JPEG doesn't support alpha
				image = image.convert('RGB')
			image.save(buffered, format=image_format)
			return base64.b64encode(buffered.getvalue()).decode('utf-8')
		except FileNotFoundError:
			if self.verbose:
				print(f"Error encoding image: File not found - {image_input}", file=sys.stderr)
			return ""
		except Exception as e:
			if self.verbose:
				print(f"Error encoding image ({type(image_input).__name__}): {e}", file=sys.stderr)
			return ""

	def _get_image_mime_type(self, image_input: Union[str, Image.Image]) -> str:
		"""Determines the MIME type of an image."""
		try:
			if isinstance(image_input, str):
				image = Image.open(image_input)
			elif isinstance(image_input, Image.Image):
				image = image_input
			else:
				return "image/png" # Default

			img_format = image.format
			if img_format == "JPEG":
				return "image/jpeg"
			elif img_format == "PNG":
				return "image/png"
			elif img_format == "GIF":
				return "image/gif"
			elif img_format == "WEBP":
				return "image/webp"
			else: # Add more formats if needed or default
				return "image/png"
		except:
			return "image/png" # Default on error


	def run(self,
			agent_query: str,
			images: List[Union[str, Image.Image]] = None,
			agent_instance: OptimizedLangchainAgent = None) -> Iterator[str]:
		"""
		Processes a query by first getting a response from OptimizedLangchainAgent,
		then uses the LAYOUT_MODEL to enhance and reformat the response,
		potentially incorporating image context.

		Args:
			agent_query: The query for the OptimizedLangchainAgent.
			images: A list of image file paths or PIL Image objects.
			agent_instance: An instance of OptimizedLangchainAgent. If None, a default one will be created.

		Yields:
			str: Chunks of the formatted response from the LAYOUT_MODEL.
		"""
		if self.verbose:
			print(f"\n--- LayoutChat: Received Query ---\n{agent_query}")
			if images:
				print(f"--- LayoutChat: Received {len(images)} image(s) ---")

		current_agent = agent_instance
		if current_agent is None:
			if self.verbose: print("--- LayoutChat: Creating default OptimizedLangchainAgent ---")
			try:
				# Pass verbose to the agent as well, assuming OptimizedLangchainAgent has verbose_agent
				current_agent = OptimizedLangchainAgent(verbose_agent=self.verbose, optimizations_enabled=False)
			except Exception as e:
				yield f"[LayoutChat Error: Could not initialize OptimizedLangchainAgent: {e}]"
				return

		# 1. Get initial response from OptimizedLangchainAgent
		if self.verbose: print("--- LayoutChat: Getting initial response from agent ---")
		agent_response_parts = []
		try:
			for chunk in current_agent.run(agent_query):
				agent_response_parts.append(chunk)
			initial_agent_response = "".join(agent_response_parts).strip()
			if not initial_agent_response:
				initial_agent_response = "[Agent did not provide a response]"

			if self.verbose:
				print("\n--- LayoutChat: Initial Agent Response (raw) ---")
				print(initial_agent_response)
				print("---------------------------------------------")
		except Exception as e:
			yield f"[LayoutChat Error: Error during agent execution: {e}]"
			return

		# 2. Prepare input for LAYOUT_MODEL
		if self.verbose: print(f"--- LayoutChat: Preparing input for {self.layout_model_name} ---")

		# Construct the human message content, including text and images
		human_message_content: List[Dict[str, Any]] = [
			{
				"type": "text",
				"text": (
					f"Please reformat and enhance the following content. "
					f"If images were provided with this request (see below), integrate their context or descriptions naturally into the text. "
					f"Focus on clarity, structure, and visual appeal using markdown.\n\n"
					f"Original Content:\n---\n{initial_agent_response}\n---"
				)
			}
		]

		if images:
			image_context_texts = []
			for i, image_input in enumerate(images):
				base64_image = self._encode_image(image_input)
				mime_type = self._get_image_mime_type(image_input)
				if base64_image:
					human_message_content.append({
						"type": "image_url",
						"image_url": {"url": f"data:{mime_type};base64,{base64_image}"}
					})
					image_context_texts.append(f"[Image {i+1} was provided. Refer to it if relevant.]")
				else:
					if self.verbose: print(f"--- LayoutChat: Failed to encode image {i+1} ---", file=sys.stderr)
					image_context_texts.append(f"[Note: Image {i+1} could not be processed.]")

			if image_context_texts:
				 human_message_content.append({
					 "type": "text",
					 "text": "\n\nImage Context Notes:\n" + "\n".join(image_context_texts)
				 })


		# Construct the full list of messages for the layout model
		messages_for_layout_llm: List[BaseMessage] = [
			SystemMessage(content=self.layout_system_prompt)
		]
		# Add LayoutChat's own history
		messages_for_layout_llm.extend(self.chat_history)
		# Add the current complex human input
		messages_for_layout_llm.append(HumanMessage(content=human_message_content))


		# 3. Stream response from LAYOUT_MODEL
		if self.verbose: print(f"--- LayoutChat: Streaming final response from {self.layout_model_name} ---")
		full_layout_response_content = []
		try:
			for chunk in self.llm.stream(messages_for_layout_llm):
				if isinstance(chunk, AIMessageChunk) and chunk.content:
					yield chunk.content
					full_layout_response_content.append(chunk.content)

			final_response_str = "".join(full_layout_response_content)

			# Add to LayoutChat's history
			# For the human part of history, we store the original agent_query combined with image indication
			history_human_content = agent_query
			if images:
				history_human_content += f" (with {len(images)} image(s))"
			self.chat_history.append(HumanMessage(content=history_human_content))
			self.chat_history.append(AIMessage(content=final_response_str))

			# Limit history size (e.g., last 5 pairs / 10 messages)
			if len(self.chat_history) > 10:
				self.chat_history = self.chat_history[-10:]

		except Exception as e:
			error_message = f"[LayoutChat Error: Error during layout model streaming: {e}]"
			yield error_message
			if self.verbose:
				import traceback
				traceback.print_exc(file=sys.stderr)
			# Add error to history to prevent repeated attempts on same state if it's a model issue
			self.chat_history.append(HumanMessage(content=agent_query + (" (with images)" if images else "")))
			self.chat_history.append(AIMessage(content=error_message))
			return

		if self.verbose: print("\n--- LayoutChat: Processing Complete ---")
		

if __name__ == "__main__":
	output_file = "output.md"
	# Example usage
	layout_chat = LayoutChat(verbose=True)
	response = layout_chat.run("What is the capital of France?", images=["screenshot.png"])
	# Empty the output file before writing
	with open(output_file, "w") as f:
		f.write("")  # Clear the file
		
	for chunk in response:
		print(chunk, end="", flush=True)
		# Save the final response to a file
		with open(output_file, "a") as f:
			f.write(chunk)
	
	print(f"\n--- LayoutChat: Final response saved to {output_file} ---")